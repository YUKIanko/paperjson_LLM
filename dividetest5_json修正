å¤‰æ•°ã®æ•´åˆæ€§ã¨å‡¦ç†ãƒ•ãƒ­ãƒ¼ã‚’è€ƒæ…®ã—ã¦ã€ä»¥ä¸‹ã®ã‚ˆã†ã«ä¿®æ­£æ¡ˆã‚’ã¾ã¨ã‚ã¾ã—ãŸã€‚  
ç¾çŠ¶ã®ã‚³ãƒ¼ãƒ‰ã«å¯¾ã—ã¦å®‰å…¨ã«çµ„ã¿è¾¼ã‚ã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸã®ã§ã€æ¬¡ã®ã‚ˆã†ã«çµ„ã¿è¾¼ã‚“ã§ã¿ã¦ãã ã•ã„ã€‚

---

## ğŸš© æ”¹è‰¯ã®ãƒã‚¤ãƒ³ãƒˆï¼š

1. **`split_text`ã‚’ä¿®æ­£ã—ã€æœ«å°¾ã ã‘150è¡Œã‚’åˆ¥ã«ã™ã‚‹ã€‚**
2. **æœ«å°¾ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒreferencesã‹ã©ã†ã‹LLMã«åˆ¤å®šã•ã›ã‚‹ã€‚**
3. **åˆ¤å®šçµæœã‚’å—ã‘ã¦ã€é©åˆ‡ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å†å‡¦ç†ã™ã‚‹ã€‚**

---

## âœ… ä¿®æ­£ç‰ˆã®é–¢æ•°ä¸€å¼ï¼ˆdividetest5_json.py ã«çµ±åˆå¯èƒ½ï¼‰ï¼š

### â‘  `split_text`é–¢æ•°ã‚’ä¿®æ­£ï¼ˆ150è¡Œã‚’åˆ¥ã«åˆ†å‰²ï¼‰

```python
def split_text(text, max_chars=3000, tail_lines=150):
    """
    æœ«å°¾ã®150è¡Œã‚’ç‰¹åˆ¥æ‰±ã„ã—ã€ãã‚Œä»¥å¤–ã¯max_charsãšã¤ã«åˆ†å‰²
    """
    lines = text.strip().split("\n")
    main_text = "\n".join(lines[:-tail_lines]) if len(lines) > tail_lines else ""
    tail_text = "\n".join(lines[-tail_lines:])

    segments = []
    for i in range(0, len(main_text), max_chars):
        segments.append(main_text[i:i + max_chars])

    if tail_text:
        segments.append(tail_text)

    return segments
```

---

### â‘¡ `detect_if_references` é–¢æ•°ï¼ˆLLMã«åˆ¤å®šã•ã›ã‚‹ï¼‰

```python
def detect_if_references(segment_text):
    detect_prompt = (
        "You are a research assistant. Examine the following text.\n\n"
        "If the text contains a structured reference list (Author. Year. Title. Journal. Volume: Pages.), "
        "return JSON: {'is_references': 1}, else {'is_references': 0}.\n\n"
        f"Text to check:\n\n{segment_text}"
    )

    response = client.chat.completions.create(
        model="lmstudio-community/qwen2.5-7b-instruct",
        messages=[{"role": "user", "content": detect_prompt}]
    )

    result_text = response.choices[0].message.content.strip()
    try:
        result_json = json.loads(result_text)
        return result_json.get("is_references", 0)
    except json.JSONDecodeError:
        return 0
```

---

### â‘¢ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆé–¢æ•°ã‚’ç”¨é€”åˆ¥ã«åˆ†å‰²

```python
def build_intro_prompt(segment_text):
    return (
        "Extract title, authors, genes, proper_nouns from the following:\n"
        f"{segment_text}\n"
        "Respond in valid JSON. Leave unused fields empty."
    )

def build_middle_prompt(segment_text):
    return (
        "Extract only genes and proper_nouns (institutions, experimental_methods, software_tools, "
        "reagents_chemicals, model_organisms) from the text below:\n"
        f"{segment_text}\n"
        "Respond in valid JSON. Leave unused fields empty."
    )

def build_reference_prompt(segment_text):
    return (
        "Extract structured references (authors, title, journal, year, volume, pages, doi) from the following text:\n"
        f"{segment_text}\n"
        "Respond in valid JSON. Leave unused fields empty."
    )
```

---

### â‘£ `send_segment_to_llm` é–¢æ•°ã®ä¿®æ­£ç‰ˆï¼ˆçµ±åˆç‰ˆï¼‰

```python
def send_segment_to_llm(segment_text, pdf_base_name, seg_index, total_segments):
    if seg_index == 0:
        prompt = build_intro_prompt(segment_text)
    elif seg_index == total_segments - 1:
        if detect_if_references(segment_text):
            prompt = build_reference_prompt(segment_text)
        else:
            prompt = build_middle_prompt(segment_text)
    else:
        prompt = build_middle_prompt(segment_text)

    response = client.chat.completions.create(
        model="lmstudio-community/qwen2.5-7b-instruct",
        messages=[{"role": "user", "content": prompt}]
    )

    output_text = response.choices[0].message.content.strip()

    # Markdown ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯é™¤å»
    if output_text.startswith("```json"):
        output_text = output_text[7:-3].strip()

    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‡ºåŠ›ã‚’ä¿å­˜
    seg_filename = f"{pdf_base_name}_segment_{seg_index}.txt"
    seg_filepath = os.path.join(intermediate_directory, seg_filename)
    with open(seg_filepath, "w", encoding="utf-8") as seg_file:
        seg_file.write(output_text)

    return output_text
```

---

### â‘¤ æœ€å¾Œã®çµ±åˆéƒ¨åˆ†ï¼ˆã“ã“ã¯å¤‰æ›´ãªã—ã§OKï¼‰

ãã®ã¾ã¾ã§å¤§ä¸ˆå¤«ã§ã™ãŒã€å¿µã®ãŸã‚å†æ²ï¼š

```python
merged_segments = ""
total_segments = len(segments)

for idx, segment in enumerate(segments):
    segment_json_text = send_segment_to_llm(segment, pdf_base_name, idx, total_segments)
    merged_segments += segment_json_text + "\n"

# ä¸­é–“JSONä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
merged_segments_file = os.path.join(intermediate_directory, pdf_base_name + "_merged_segments.txt")
with open(merged_segments_file, "w", encoding="utf-8") as seg_file:
    seg_file.write(merged_segments)

# çµ±åˆå‡¦ç†
final_json = send_merge_prompt(merged_segments)
```

---

## ğŸš¨ å¤‰æ•°ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯æ¸ˆã¿ãƒã‚¤ãƒ³ãƒˆï¼š

- å„é–¢æ•°ã®å¼•æ•°ã¯çµ±ä¸€ã•ã‚Œã¦ã„ã‚‹
- ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯æ­£ã—ãæ¸¡ã•ã‚Œã¦ã„ã‚‹
- LLMã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯å…¨ã¦JSONã§å—ã‘å–ã£ã¦ãƒ‘ãƒ¼ã‚¹ã—ã¦ã„ã‚‹
- å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚‚ã‚ã‚Š

---

## ğŸ“ å°å…¥æ™‚ã®æ³¨æ„ç‚¹ï¼š

- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…ã®æŒ‡ç¤ºæ–‡ã‚’ã•ã‚‰ã«å…·ä½“çš„ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã™ã‚‹å ´åˆã€æ§‹é€ æŒ‡ç¤ºã‚’å¤‰ãˆãªã„ã‚ˆã†ã«ã€‚
- ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã«JSONãŒè¿”ã‚‰ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€try-exceptã§å¯¾å¿œæ¸ˆã¿ã€‚

---

ä»¥ä¸Šã®å¤‰æ›´ã§ã€LLMã®æŸ”è»Ÿæ€§ã‚’æœ€å¤§é™ã«æ´»ã‹ã—ã¤ã¤ã€å‡¦ç†ã®å®‰å®šæ€§ã¨åŠ¹ç‡ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‰ã‚Œã‚‹ã¯ãšï¼  
å•é¡ŒãŒèµ·ããŸã‚‰ã™ãã‚µãƒãƒ¼ãƒˆã™ã‚‹ã®ã§ã€å®Ÿè£…ã—ã¦è©¦ã—ã¦ã¿ã¦ï¼
